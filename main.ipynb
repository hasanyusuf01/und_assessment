{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CwY3IzxOiny8",
        "outputId": "f725315e-785d-437d-8e35-0d9482b1850c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "!pwd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_Xcm5BbiuTX",
        "outputId": "75589313-fc66-43b2-a420-806d4fe522ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdrive\u001b[0m/  \u001b[01;34msample_data\u001b[0m/\n"
          ]
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2BAmwWWiOmbm",
        "outputId": "d4a9a2e4-a8a7-4ffe-dc8c-f313c09e0378"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Projects/rl\n"
          ]
        }
      ],
      "source": [
        "cd drive/MyDrive/Projects/rl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MfDENPSPTvQe",
        "outputId": "bad7ba7a-2bd1-488c-b916-5da9f512744a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'DDPG-Pytorch'...\n",
            "remote: Enumerating objects: 51, done.\u001b[K\n",
            "remote: Counting objects: 100% (51/51), done.\u001b[K\n",
            "remote: Compressing objects: 100% (32/32), done.\u001b[K\n",
            "remote: Total 51 (delta 17), reused 46 (delta 15), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (51/51), 1.78 MiB | 12.15 MiB/s, done.\n",
            "Resolving deltas: 100% (17/17), done.\n"
          ]
        }
      ],
      "source": [
        "# !git clone https://github.com/sainijagjit/DDPG-Pytorch.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uKTnSpeUNvw",
        "outputId": "4e52d3a5-19a7-4ac6-f3bd-1c817b64a486"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Projects/rl/DDPG-Pytorch\n"
          ]
        }
      ],
      "source": [
        "cd DDPG-Pytorch/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6-T5PxjAffrY",
        "outputId": "41e07d42-e222-4127-eb23-e647dd42d896"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gym in /usr/local/lib/python3.11/dist-packages (0.26.2)\n",
            "Requirement already satisfied: box2d-py in /usr/local/lib/python3.11/dist-packages (2.3.8)\n",
            "Requirement already satisfied: pygame in /usr/local/lib/python3.11/dist-packages (2.6.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.3.0)\n",
            "Requirement already satisfied: cloudpickle>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from gym) (3.1.1)\n",
            "Requirement already satisfied: gym_notices>=0.0.4 in /usr/local/lib/python3.11/dist-packages (from gym) (0.0.8)\n"
          ]
        }
      ],
      "source": [
        "# !apt-get install -y swig\n",
        "!pip install gym box2d-py pygame\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 369
        },
        "id": "lh2_7_33icVA",
        "outputId": "fab9cf78-05b1-40a3-e142-bfc11eaf794a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting numpy<2\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/61.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.3.0\n",
            "    Uninstalling numpy-2.3.0:\n",
            "      Successfully uninstalled numpy-2.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "dopamine-rl 4.1.2 requires gym<=0.25.2, but you have gym 0.26.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-1.26.4\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "45fd22981d0e426e9a788229dc0830bd",
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "!pip install --upgrade \"numpy<2\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pYmMTHQXVGE_"
      },
      "outputs": [],
      "source": [
        "# point_particle_env.py\n",
        "\n",
        "from typing import Optional\n",
        "import numpy as np\n",
        "import gym\n",
        "from gym import spaces\n",
        "from gym.utils import seeding\n",
        "import pygame\n",
        "from pygame import gfxdraw\n",
        "\n",
        "class PointParticleEnv(gym.Env):\n",
        "    \"\"\"\n",
        "    Continuous 2D navigation with interior obstacles and boundary walls.\n",
        "    - State: [x, y, heading] (plus flattened obstacles if obs=True)\n",
        "    - Action: heading angle in degrees [action_min, action_max]\n",
        "    - Reward:\n",
        "        * +goal_reward on reaching the goal\n",
        "        * -obstacle_penalty if bumping an obstacle\n",
        "        * -wall_penalty     if pushing against a boundary\n",
        "        * otherwise = -distance_to_goal\n",
        "    - Episode ends (terminated) on goal; truncated on time-limit.\n",
        "    \"\"\"\n",
        "    metadata = {'render.modes': ['human', 'rgb_array']}\n",
        "\n",
        "    def __init__(self,\n",
        "                 size=(50, 50),\n",
        "                 goal=None,\n",
        "                 exploring_starts: bool=False,\n",
        "                 obs: bool=False,\n",
        "                 action_range=(0, 360),\n",
        "                 max_episode_steps: int = 500,\n",
        "                 obstacle_penalty: float = 10.0,\n",
        "                 wall_penalty: float = 10.0,\n",
        "                 goal_reward: float = 100.0):\n",
        "        super().__init__()\n",
        "        # —— seeding for reproducibility\n",
        "        self.seed()\n",
        "\n",
        "        # —— env parameters\n",
        "        self.size = np.array(size, dtype=np.float32)\n",
        "        self.speed = 5.0\n",
        "        self.goal = np.array([45.0, 45.0], dtype=np.float32) \\\n",
        "                    if goal is None else np.array(goal, dtype=np.float32)\n",
        "        self.exploring_starts = exploring_starts\n",
        "        self.obs = obs\n",
        "        self.action_min, self.action_max = action_range\n",
        "\n",
        "        # —— penalties & rewards\n",
        "        self.obstacle_penalty = obstacle_penalty\n",
        "        self.wall_penalty     = wall_penalty\n",
        "        self.goal_reward      = goal_reward\n",
        "\n",
        "        # —— time‐limit bookkeeping\n",
        "        self.max_episode_steps = max_episode_steps\n",
        "        self.current_step      = 0\n",
        "\n",
        "        # —— action & observation spaces\n",
        "        self.action_space = spaces.Box(\n",
        "            low  = np.array([self.action_min], dtype=np.float32),\n",
        "            high = np.array([self.action_max], dtype=np.float32),\n",
        "            dtype=np.float32\n",
        "        )\n",
        "\n",
        "        # define some interior rectangular obstacles (x1,y1,x2,y2)\n",
        "        self.obstacles = [\n",
        "            (12, 12, 25, 15),\n",
        "            (25, 25, 27, 37)\n",
        "        ]\n",
        "\n",
        "        # observation space: [x, y, heading] + obstacles if obs=True\n",
        "        if self.obs:\n",
        "            obs_low  = np.zeros(4 * len(self.obstacles), dtype=np.float32)\n",
        "            obs_high = np.concatenate((self.size, [360])).astype(np.float32)\n",
        "            self.observation_space = spaces.Box(\n",
        "                low  = np.concatenate(([0, 0, 0], obs_low)),\n",
        "                high = np.concatenate((obs_high, obs_low + self.size[0])),\n",
        "                dtype=np.float32\n",
        "            )\n",
        "        else:\n",
        "            self.observation_space = spaces.Box(\n",
        "                low  = np.array([0, 0, 0], dtype=np.float32),\n",
        "                high = np.array([*self.size, 360], dtype=np.float32),\n",
        "                dtype=np.float32\n",
        "            )\n",
        "\n",
        "        # internal\n",
        "        self.state  = None\n",
        "        self.screen = None\n",
        "\n",
        "    def seed(self, seed: Optional[int]=None):\n",
        "        \"\"\"Gym-style seeding.\"\"\"\n",
        "        self.np_random, seed = seeding.np_random(seed)\n",
        "        return [seed]\n",
        "\n",
        "    def reset(self, *, seed: Optional[int]=None, options=None):\n",
        "        \"\"\"Reset environment; return (obs, info).\"\"\"\n",
        "        if seed is not None:\n",
        "            self.seed(seed)\n",
        "        self.current_step = 0\n",
        "\n",
        "        if self.exploring_starts:\n",
        "            x       = self.np_random.uniform(0, self.size[0])\n",
        "            y       = self.np_random.uniform(0, self.size[1])\n",
        "            heading = self.np_random.uniform(self.action_min, self.action_max)\n",
        "        else:\n",
        "            x, y, heading = 10.0, 10.0, 0.0\n",
        "\n",
        "        if self.obs:\n",
        "            flat_obs   = np.array(self.obstacles).flatten().astype(np.float32)\n",
        "            self.state  = np.concatenate(([x, y, heading], flat_obs))\n",
        "        else:\n",
        "            self.state  = np.array([x, y, heading], dtype=np.float32)\n",
        "\n",
        "        return self.state, {}\n",
        "\n",
        "    def is_collision(self, x: float, y: float) -> bool:\n",
        "        \"\"\"Check interior obstacles only.\"\"\"\n",
        "        for x1, y1, x2, y2 in self.obstacles:\n",
        "            if x1 <= x <= x2 and y1 <= y <= y2:\n",
        "                return True\n",
        "        return False\n",
        "\n",
        "    def step(self, action):\n",
        "        \"\"\"Apply action, return (next_state, reward, terminated, truncated, info).\"\"\"\n",
        "        self.current_step += 1\n",
        "\n",
        "        new_state, reward, terminated, info = self._simulate_step(self.state, action)\n",
        "\n",
        "        x, y = new_state[:2]\n",
        "        # interior obstacle penalty\n",
        "        if self.is_collision(x, y):\n",
        "            reward -= self.obstacle_penalty\n",
        "        # boundary wall penalty\n",
        "        if not (0 <= x <= self.size[0] and 0 <= y <= self.size[1]):\n",
        "            # (shouldn’t happen if we clip, but just in case)\n",
        "            reward -= self.wall_penalty\n",
        "\n",
        "        # goal bonus\n",
        "        if terminated:\n",
        "            reward += self.goal_reward\n",
        "\n",
        "        # truncation on time-limit\n",
        "        truncated = (self.current_step >= self.max_episode_steps)\n",
        "\n",
        "        # update state\n",
        "        self.state = new_state\n",
        "\n",
        "        return new_state, reward, terminated, truncated, info\n",
        "\n",
        "    def _simulate_step(self, state, action):\n",
        "        \"\"\"Compute next_state, base_reward, terminated (no penalties here).\"\"\"\n",
        "        pos     = state[:2]\n",
        "        heading = float(action[0])\n",
        "\n",
        "        dx = self.speed * np.cos(np.radians(heading))\n",
        "        dy = self.speed * np.sin(np.radians(heading))\n",
        "        new_x = pos[0] + dx\n",
        "        new_y = pos[1] + dy\n",
        "\n",
        "        # detect interior obstacle or boundary\n",
        "        hit_obstacle = self.is_collision(new_x, new_y)\n",
        "        hit_wall     = not (0 <= new_x <= self.size[0] and 0 <= new_y <= self.size[1])\n",
        "\n",
        "        # roll-back if collision or out-of-bounds\n",
        "        if hit_obstacle or hit_wall:\n",
        "            new_x, new_y = pos\n",
        "\n",
        "        # clip to exact bounds\n",
        "        new_x = np.clip(new_x, 0, self.size[0])\n",
        "        new_y = np.clip(new_y, 0, self.size[1])\n",
        "\n",
        "        if self.obs:\n",
        "            obs_data  = state[3:]\n",
        "            new_state = np.concatenate(([new_x, new_y, heading], obs_data))\n",
        "        else:\n",
        "            new_state = np.array([new_x, new_y, heading], dtype=np.float32)\n",
        "\n",
        "        # base reward = negative distance to goal\n",
        "        distance   = np.linalg.norm(new_state[:2] - self.goal)\n",
        "        base_reward = -distance\n",
        "\n",
        "        # termination when close to goal\n",
        "        terminated = (distance < 5.0)\n",
        "\n",
        "        return new_state, base_reward, terminated, {}\n",
        "\n",
        "    def render(self, mode='human'):\n",
        "        \"\"\"Draw agent, goal, obstacles, and walls.\"\"\"\n",
        "        screen_size = 600\n",
        "        scale = screen_size / max(self.size)\n",
        "\n",
        "        if self.screen is None:\n",
        "            pygame.init()\n",
        "            self.screen = pygame.Surface((screen_size, screen_size))\n",
        "\n",
        "        surf = pygame.Surface((screen_size, screen_size))\n",
        "        surf.fill((22, 36, 71))  # background\n",
        "\n",
        "        # draw boundary walls (as gray frame)\n",
        "        wall_thick = 5\n",
        "        pygame.draw.rect(surf, (100,100,100), (0, 0, screen_size, wall_thick))  # top\n",
        "        pygame.draw.rect(surf, (100,100,100), (0, 0, wall_thick, screen_size))  # left\n",
        "        pygame.draw.rect(surf, (100,100,100), (0, screen_size-wall_thick, screen_size, wall_thick))  # bottom\n",
        "        pygame.draw.rect(surf, (100,100,100), (screen_size-wall_thick, 0, wall_thick, screen_size))  # right\n",
        "\n",
        "        # draw goal\n",
        "        gx = int(self.goal[0] * scale)\n",
        "        gy = screen_size - int(self.goal[1] * scale)\n",
        "        gfxdraw.filled_circle(surf, gx, gy, int(scale*2), (40,199,172))\n",
        "\n",
        "        # draw obstacles\n",
        "        for x1, y1, x2, y2 in self.obstacles:\n",
        "            rx = int(x1*scale)\n",
        "            ry = screen_size - int(y2*scale)\n",
        "            w  = int((x2-x1)*scale)\n",
        "            h  = int((y2-y1)*scale)\n",
        "            pygame.draw.rect(surf, (128,128,128), (rx, ry, w, h))\n",
        "\n",
        "        # draw agent\n",
        "        ax = int(self.state[0]*scale)\n",
        "        ay = screen_size - int(self.state[1]*scale)\n",
        "        gfxdraw.filled_circle(surf, ax, ay, int(scale*1), (228,63,90))\n",
        "        # heading line\n",
        "        end_x = ax + int(10*np.cos(np.radians(self.state[2])))\n",
        "        end_y = ay - int(10*np.sin(np.radians(self.state[2])))\n",
        "        pygame.draw.line(surf, (255,255,255), (ax,ay), (end_x,end_y), 2)\n",
        "\n",
        "        canvas = pygame.transform.flip(surf, False, True)\n",
        "        self.screen.blit(canvas, (0,0))\n",
        "\n",
        "        if mode=='human':\n",
        "            pygame.display.flip()\n",
        "            return None\n",
        "        elif mode=='rgb_array':\n",
        "            arr = pygame.surfarray.pixels3d(self.screen)\n",
        "            return np.transpose(arr, (1,0,2)).astype(np.uint8)\n",
        "        else:\n",
        "            raise ValueError(f\"Render mode {mode} not supported\")\n",
        "\n",
        "    def close(self):\n",
        "        \"\"\"Shutdown pygame.\"\"\"\n",
        "        if self.screen is not None:\n",
        "            pygame.display.quit()\n",
        "            pygame.quit()\n",
        "            self.screen = None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YCb48-rXVUIS",
        "outputId": "b68380e7-ec5d-488d-eb94-c2f9c821468a"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<video width=\"600\" height=\"600\" controls autoplay loop>\n",
              "  <source type=\"video/mp4\" src=\"data:video/mp4;base64,AAAAIGZ0eXBNNFYgAAACAE00ViBpc29taXNvMmF2YzEAAAAIZnJlZQAAKottZGF0AAACrgYF//+q\n",
              "3EXpvebZSLeWLNgg2SPu73gyNjQgLSBjb3JlIDE2MyByMzA2MCA1ZGI2YWE2IC0gSC4yNjQvTVBF\n",
              "Ry00IEFWQyBjb2RlYyAtIENvcHlsZWZ0IDIwMDMtMjAyMSAtIGh0dHA6Ly93d3cudmlkZW9sYW4u\n",
              "b3JnL3gyNjQuaHRtbCAtIG9wdGlvbnM6IGNhYmFjPTEgcmVmPTMgZGVibG9jaz0xOjA6MCBhbmFs\n",
              "eXNlPTB4MzoweDExMyBtZT1oZXggc3VibWU9NyBwc3k9MSBwc3lfcmQ9MS4wMDowLjAwIG1peGVk\n",
              "X3JlZj0xIG1lX3JhbmdlPTE2IGNocm9tYV9tZT0xIHRyZWxsaXM9MSA4eDhkY3Q9MSBjcW09MCBk\n",
              "ZWFkem9uZT0yMSwxMSBmYXN0X3Bza2lwPTEgY2hyb21hX3FwX29mZnNldD0tMiB0aHJlYWRzPTMg\n",
              "bG9va2FoZWFkX3RocmVhZHM9MSBzbGljZWRfdGhyZWFkcz0wIG5yPTAgZGVjaW1hdGU9MSBpbnRl\n",
              "cmxhY2VkPTAgYmx1cmF5X2NvbXBhdD0wIGNvbnN0cmFpbmVkX2ludHJhPTAgYmZyYW1lcz0zIGJf\n",
              "cHlyYW1pZD0yIGJfYWRhcHQ9MSBiX2JpYXM9MCBkaXJlY3Q9MSB3ZWlnaHRiPTEgb3Blbl9nb3A9\n",
              "MCB3ZWlnaHRwPTIga2V5aW50PTI1MCBrZXlpbnRfbWluPTEwIHNjZW5lY3V0PTQwIGludHJhX3Jl\n",
              "ZnJlc2g9MCByY19sb29rYWhlYWQ9NDAgcmM9Y3JmIG1idHJlZT0xIGNyZj0yMy4wIHFjb21wPTAu\n",
              "NjAgcXBtaW49MCBxcG1heD02OSBxcHN0ZXA9NCBpcF9yYXRpbz0xLjQwIGFxPTE6MS4wMACAAAAF\n",
              "DmWIhAAR//73iB8yy2n5OtdyEeetLq0fUO5GcV6kvf4gAAADAAADAAIceCvyHWMDfpugAAA1oAac\n",
              "OeT/4M0/8QDOttXYB27Mw9J9mvlUiCU5ySI2SzjfT9sOPojj7Kgits/PMcxN/d+glLBL7AC/eyUz\n",
              "SyzwoENNO9C/LuvtZjDQayXjFzU1szYo1o6wYDEcJ0vi9iUPrnA7V71AAAAU5z+vdkukYGqv7Z2T\n",
              "H0L/KK20apcYzoXwgUelT1o0LEUDc5xkaeBOoR6RZAa+2aAX1gIAEtuc1iX4GVRKj4ggmar496Ob\n",
              "FTZGwUdHIAbz8puQwAosMWCIbVONKkXwBj3qtl/qBqBHzCDbV6/0+DoMzrHtPKk4l6ug/usePVOV\n",
              "qm+OOBQHt7eY0UjuKm9iA/d3LoixOb7ud97gedgFIu+oPnG+6Gyt2O44ut7lzXD2zdpuLK76oGQa\n",
              "wI9FMCOuvBGJI9Cpyd+IGIc3dTyQAm7dinPiilVyFIuJn29kOTGuboDxapaoUWkMxUHZqL8vX51Q\n",
              "Y3RLijXYVKTi0aZA+BdVPBsiyRLt8z4Eu8CDGjTg8JEpIeVVD5BwxZeEeD7qoBq8Ab3yxaMRaPsh\n",
              "lCuSdXxjzy5V5YXwSe4DG8EvVHoFBgY4AbNiBn7EqUDdSixrQSPGajkIHgSGCDiW3W+AVxvGtNsf\n",
              "s9GtavTk03mcL/k7CHRI7RMaN7oCOWeUIvbEMyocjntEHCHGPcVWu2YmrvfEyckW9ajlCkDcvZTx\n",
              "f5O9AcNmxIwyFu8fM2/2OLAJJKYSxGrzcI3es5HL2ube7cqPdv+m7UG6Mrl0OPvxSphrDLfgPVDh\n",
              "feknb0iINSR8RDDYgLuaQPNFvllRMExeNKlJfCKVFgjc+3Ix6xiu0hgCBJBSMRHAdwwOjPNbisOj\n",
              "7lTuFnHoPKG28P25lAcxrPAFemTjO/S6nD8M+q1NlqraMj6c/fo3XQZqowIJn3L0KG5Qv85YCgG2\n",
              "/rvPwh/T2L7f+DiTOsD0Vnallwr153Fcydja1daB9Ge47R5KG3XwJP5sgdoqKFCT6aj+tILtEl+f\n",
              "AIEz8J/V2HDp+vcQg166GTfqNdSh3F1yI+5+9dr7uKyRRYY6jX8T3QEZF2nzup24iCcOMJ6ZQ7Sx\n",
              "OvINjqWZumHQCaLb2GFLmH7KwUrbda6xR3TwxX+/UGzWLQNKj1BrayQ6nCa+cxwaRDVZn+KaniK1\n",
              "nxAnp3a8I3qBJ43c1RoADVR/QXkXGhyp4u7XkxMpfok4l9qg6pp3gqNeA6tti7iZ46wAYYnjqN/I\n",
              "GeLQgZSsF+J3U4xdwl+XpKxnU/vHPjgiKCLwciTKMr3MSgJJ1Tlpvyw0Rk5soQE9z2CSb11rJJGH\n",
              "xoERMOCFrf6cKuYY18LpWQN+PCCvCAQUfMwrB77CL3EGnJLFrZkdytijaHiJBQc0QdUG4BQ9A17N\n",
              "Y9Nw80G5k15tOxYrhLBK9MW/aLV/0xLc/iU4103W0V8cx9/pZDAjoAgjgKY0xm7ZPqIGbxbkkA/6\n",
              "HqHBke38o2/kCmGKFFxIs0pVVBAvKU7Cqp4EHCTlzY7nmAAAGd8z/NPFIRENmNQSVZ2HJQyraTEf\n",
              "hZerAnlDs18SDnxEkofFg8VIe+uhYCtfuh3ihRtotBeuZpzgMOSq3q/ccAs/+c5tUsL1zppsm9f6\n",
              "93xi3H7iAvsbHznBnaAWOa5FHA9YVxdIAAADAAGEuQAAAwAT4AAAN6EAAAD0QZokbEEf/rUqgAJD\n",
              "bamGjwT/4+LK3pmDq9ulmedgkjPygAymNe03DbBtno2bnnfSWfNyERCWgtauSL3AVEjJL7Zciv5p\n",
              "m0tgMPtSLUdyEVbqKyC4jlEKIVxZFzaP/Oy+RtvE1SXjhS/VTGw41jJO8fV31TLP+LDatynplNiO\n",
              "yDP9I/dAQTQn/6qTZGqJ66ygVBQIYIF1wxoX2MbY7EmKGRxv1rHbzP5WRhAkLTzjQ3islMAA35v4\n",
              "8vPuwZLP9rzvqC6SYVy4yRBkdNFsCE8Et/waiYPUBNXAAhe0yVJ+mMAcu/jD9pqopOGSvW5QHcaC\n",
              "FDNHHAAAAFdBnkJ4h38ACMOT+QgrEGozjgBxmx+Gb4oz2gn9u1ubVgAbVIkrIQrYx1kP0GIRu1Y9\n",
              "Jddu+ik6EiFrHLXU167ogi6TSNbKIh7bkabsBf3JQAAkfdeADAkAAABQAZ5hdEN/AAyPV9uOKc1m\n",
              "1OFuNXWAD8ZYs1H8IdKN9pYkyk3jaYiUaYN6JmdbAf6MVKCgm00r4yTmcVnATPMODhXxYoN4dTq6\n",
              "AAE+mvrHg/wAAABfAZ5jakN/AAADAS3Gx2EhABcoLAZXLd6bmz6C7PZn93YAIM6qqw9B/bUtDLIQ\n",
              "XbMteOFFZsWua84sfa1H5TiQlMxsvSByUE6KFiMMN2MQpkl1wtTE0nJBJtFD1AAAB3UAAADpQZpo\n",
              "SahBaJlMCCP//rUqgAAAkDdSwAW9cSkwKSg3RtSXQoZ4QWruKv8fkdPDbZfdYBCQSeck1BORhpmB\n",
              "f6BCp+UogKLFMhcw99LQG2UyQ82nwCyE1qrZeBprPNwVADs8kqNWH95caG9AmcCT/szCzDQsG6IN\n",
              "j+dn8TnE3wG+N5ko1e0Q/vzvatjt18oVkJr9gJ6TEc12FfsLUvlUc0vmpH443PDwOzwO+15n9crM\n",
              "xpvB+9zhAybwAQdG3/+ckzdLve/UMXoYn4jBL0tHOf1liDGuBpUWNWSm2MYOGyzKRi1dH4jMOAAA\n",
              "DLkAAADKQZ6GRREsO/8AAAW5WAbPlv+4AOiEcWhz/F92jD6AD+jvS+gJHclg02/+P9jRnOLWrYaK\n",
              "RA8bMFxcSWQ5pYeUom7ZyI7+5BDS2+29+ZiTZgkiNmOqG9mC4Ig+eP03duwrSnZkEGY8HwExxylQ\n",
              "C4s3WMzXyWXDhqas7bpOzYcEe/xpq6NSz6ZJA3xS4iSMeBRc+u6BYb+te4JKS6z1lgvMIhvrqgB0\n",
              "U5TUqjUV62pyu4pyDFt8yKRs4sV1YWjoVX/teESu4gAAAwD0gQAAAL8BnqV0Q38AAAMAds97WIC2\n",
              "eQhFFRBTLboL4wylsMABLVpVfMxcUzj475SpKKKUl3R8tRFhXUuaIIlVi1PfX8RQgRbxs4058hjJ\n",
              "GMfuIfi8juWjaMh6sD4yiguEEyE027GmjZj4gStCh/FKqSX4mgHoop8cwdz7xU7MLlSKYwjfJj1Q\n",
              "oZGwhqtqNwncbsCxR50iu+w+3jwx8jt/wXPX11oJ9ckb0mNervB64Qu7bKXM8LiI3aB+OthYP1BN\n",
              "AAAEnQAAAFABnqdqQ38AAAfwogt2Ux8nwAfnIzN8m8m/4+tQxy7SYzLomHZGQvRQSij0eqxvV/O1\n",
              "ttfQQmbvAaIozwgvkMP0Xcsm6wTif3dOGTsAAAMA/wAAAMVBmqxJqEFsmUwII//+tSqAAACQ/Zp4\n",
              "fTveX44+D5iGC/5XcE785E5QALtIxT6olAINBw30hZfPPqUEaHCNqJVlLk3uGdkgMsLFC7PsrmUS\n",
              "m7KGvzb26d0mzUsPR7e3xPcq2lI+aievHDQ0og02dmj4rmjTQa6Mv05citBHcMVPpdNeccjYO04T\n",
              "bA13etWYARKHaoTYkP3VC+9+txlH3kzE63a/LmwnJEIt2a5Z8RvYPVMMyfkI0rT8Ha4bWE32x90u\n",
              "UAAEbAAAAMFBnspFFSw7/wAABbnDA2T6mniI9HtndrBeAKQhErlPXVtrVCC/2/IwfILsjTAXBsLZ\n",
              "MxnBu09BINqPBbp5vmwCdhz8bHLtIinv0UJRyP8m19cWBJQG1RwQXmLV3gb2AnxJi2eJ1EQgkqvH\n",
              "cTmfN3xxAdDcLpeP/OlfnnJD0a9pKu5ooSqsF8SEvnx64ZhS2jwe94ZTjNMhKTTVgngniwmgTIwC\n",
              "Ac5V0t5Oh8l0FhH7Hm8Gvmy7+lDQ4NcT+XGAAPSBAAAA0QGe6XRDfwAAB+9PC22b9PihKSKcAQF5\n",
              "xiFQHFAA/OF0LL7XVDTqjEJ8qTWzJhXoXjKZKB1gvh/hKj6OSq66f7DUDdeu9DQMc0/mWjRIPxvy\n",
              "qrOdeNjFE0Skjy/ZD2VAezOf5VBEsF34iGwtvIppe+KsC+WtiC5CCxPMtbAgdb2Bah8TDycTtRf3\n",
              "5n078XCANbqbr5Thy9L4wLlb5QcmEjAn8HkozG0FYjUAZWPEnVjmCnj2TQVy44Z/NF8PG6RCoIUT\n",
              "jcoKi0erK6uqK/gAAHTAAAAAywGe62pDfwAAB/Ch8aJBbMc4NLAzJNOMk7P4Yu20oAjK5CAaArwG\n",
              "8EIIigyyZKdJGUVczgKoICtZ0n+HUflGqWFiQ+qesf9IjepEE1BrHB9wMRJtvBQU24+i/P6607Yr\n",
              "cTuNYj25fDC2UCW7lVDAiYJFO0VdiVaHxsD/IB1Y/TcquIjMbdgm0tY4IaMt4PSsWW72Eb+2ID3S\n",
              "JQX+f8fj01k9TWite8QWPvFh8UldhG7PSfLPNyVwgWM9iCtBvMg74IZESzA7BbdAANmAAAAA3EGa\n",
              "8EmoQWyZTAgj//61KoAAAAMADk/HzJXdCbcCACxOAu2X8GQuAAPzip39uoVeEXOcJlUiuYGRxeLH\n",
              "bavdJuoCluTWIslRhddZJsOf170maDWs27lFMa5Ei9Ys9D2Y1KHY8Za+iXuuXXRyihG0zGXCVLy2\n",
              "FWIRQU0CxwXgTvZEp7s0ngLDx5EiHO+UzwktCPmBGcdfNZjz6QhLIsM1utwdt6pDU9OHVXFSjCyJ\n",
              "kVBQ3iiTIhOsZWof/oJ0A5tLZVOKzAikFA3Z9UqzGcFV9629/Fvrfrk5sHI0od0AAADHQZ8ORRUs\n",
              "O/8AAAW5wv+yyqzMZoZjLc1gDbRWpZR9R3PW7gFCQihwCGzBZNvYi673fVagv1z95TCkJ2b363w8\n",
              "myR4Scw1LNYB+VegZmO2nieS7nkFr+/XpVCrhW0GI3soVZcVmcr6HGT4+2GQnrk8umxbDnTmTOBF\n",
              "M9XR25x5Bcv0SnaG7N17+IeQQW+HOaSOHqzPDTXWrb9rhuY0stBOvKDHnFAfGq7OLYqQJ7kAXMJN\n",
              "kjvYqX8JD2l7HiGyGgDWVmt/9ZgBSQAAAMoBny10Q38AAAfvTvGhRMVABgyuWu78LJM5YUAmKJgU\n",
              "7VlSmZa8r2dIc/UyK/rkN0d0z1hRjf9eLY7UXhOnh5sg9+rms7pTHS5uo6SfYYfitL3jKBSCCLi7\n",
              "64RO/94TscDpo8aj86r+MXYx8gRlAmyT9RiMpI0cBUjfzXIYzB5fOxnGq05lYX75JhowjQsx1zdG\n",
              "5b0YZoSN06U+0GtmXnSBhGRm4J0krAvYZr1SCiGoetJOR3c9TNysF8pw78t07uBVZgtPyoDLEApJ\n",
              "AAAAzgGfL2pDfwAAB/Ch8aJBbPB676AN48X2kasen8dQAH8Hv7URMZjgeVSNcMDfMFYh8ENCPDjK\n",
              "Ufx/3o0aAvrnIHNGc6Dc+eKuvTOK/SXZ4RS/lapJ0KP8OIXbPNnhwbTrYZpIWlJGN2PcB7OJ9KuN\n",
              "EIBSVrNLsgwXSif/a/X3Cu+q2S3wekLKFJut+/bTr4YssoZOb9DyKLODdVdrTUwAArXilkCQXBry\n",
              "h+XOtKAAx0vEwtKiiIeub9X3M9pq1nyYFw2VfEVuQqazUpk4ABgQAAAAx0GbM0moQWyZTAgj//61\n",
              "KoAAAAMAAEp+zcy9mw/Dqs1tOcc7ffw2q5IAF9fRiu0AFZ4nSFFngQCowAHEDoY5TcPfTuxNrj5T\n",
              "g8tJJbxp5m46rtcB5yPggXZmpRbL9tlbejQF5wMr7+H337a3ca4XedT5XOICxtRglp/WggX2ll+v\n",
              "3yL1YoNdgcD7e84WUSzUhDlDRP+c6Trer0naI+hGPRYH6IxFzYYmWh2L9vpguhTDf4NNNqgmykv3\n",
              "tLeftsXEf3y+TIYwNYAAAADVQZ9RRRUsN/8AAAfxSqJor3xUeO3DFkB74LsxmFcemcId56Ro/tGA\n",
              "Ccj3KY6/Vz1J8WPNzzfzdNjSzhooKkdVT7Gy0cQ8TadtNp9gAZtIzLawfLZGIsUl2SIUmbK2JpJ5\n",
              "HagdKCHLWpGBRKU1fcw4wSl2omRnJkjEC7l0Ate9qySg2mV5OAdKx8k9RYkJki3wqmBVjjkrdDZM\n",
              "mc9o7BimAr9SBjxLM+PQS0DFPzo27fr40QNvEb/CogIxHWHeN0krKreXh8q61GL6RVq2efjkvOKq\n",
              "iwVtAAAAzAGfcmpDfwAAB/Ch8aJBbPB676AMxX8GO7lYVMElQIwpzCtHalY0EaOfMVWOTp+wmUzo\n",
              "DaZd+NKSWtVMIbqTsq5RGKh/BNpVwrFDcqk6QQaFiNaZsMYjmgbILrDhcho4qfo/lDvOF1+S7GAK\n",
              "6/UBNjl5H2dmmnvQZRseg5nuuv16TNwt6SbR1ffDHH5PZUwJ+kc94DhppCxGtmrS8tPtqD0zIgZQ\n",
              "sr67KFIpnTeON0tBYEX2xNWvfy09vDD9H1txQa5QOTS7LpzBguGhnwAAALxBm3dJqEFsmUwII//+\n",
              "tSqAAAADAAADADVfHzJXbv64GEWLMr/BI8gFDvTJmjPL2rthCEvroULbS7DdNhrPcJ7uhQYrCH5d\n",
              "TOIuo/ORG4ePeVt6JkKhq7i+2q7Z1uKT07QM99U7ZEwNzpvOmOC8aJQ8ogv7xRaQELMvB5TotqMz\n",
              "tJFi9mvmQoub5uZVVS98STE2VSmDSldbvyubBq1dNczrTsQ4LNdK/GRBUSEfVfS/3vNj4ZZ+lXQi\n",
              "rpDqCAAAAExBn5VFFSw7/wAABbnC/7LKrM76KCggG/T9zKdYbxlnOLXLVIQA1iskuv4RUQPGdDY3\n",
              "Dq8z3tj08s+NRbtVEYhRbbMsDkBgu0YoweZVAAAAMwGftHRDfwAAB+9O8aFExUAF3z0rcJJTmgJq\n",
              "c82OdGsmR/ndgAhemz2rYmtrr185ewNW0AAAAGgBn7ZqQ38AAAfwofGiQWzweu+gDLhLrA8AR8c1\n",
              "fk2w4W71FXE+uuDrdyzKfn5DY6l0+00L0VXhPy3ijPaDyW3vILZUxwnaJAiWVdfvLwjvzr2HSoCy\n",
              "j3mmr+qqJ9luS1fH1wry4VaMqQAAAL9Bm7tJqEFsmUwII//+tSqAAAADAAADA323qbVC2jpj6ABd\n",
              "OznNn4vd8hrBlX/2NsWeX4p92tjW5K8lpyzT7uQ8vOSsB/b2A2beFPvPfNAQKMIWGtdF+Prnr+/A\n",
              "VIn2fI5R4gGsRoaKa79/xjukwr9O3RdLx0ZLX6QJyqc6xqAqmXIwkKTaNbYUW3oSo7nP6zBCv39v\n",
              "u6L5j9YCKAKgK06LVqPLM1268Q5bocXPhoDbd6okiLg0Dqari2nPBzayNQAAANhBn9lFFSw7/wAA\n",
              "BbnC/7LKrM76KCggHATSSttgdvN1DzE+G3XqAYAWU74qyjO/48ojqL9URBt/umvN6YRaAeAzJx3F\n",
              "h3ED/kbwAIHUY8Mag9NHVMhqZxCPyTg+5HVrjReyGaCkJqqf9ZKE8lWUvgjfxFQO8pTOKskFoKMd\n",
              "0nboodd9kjTAJgqGdZXX1rK7oAnKYIVcsp1vYirccp+ZZUowOCtywuOhGLmS9anGNiHI61db02C1\n",
              "YBVC5FLyb6gkmV333MzHoofjTzReu/+iR8qDJNvwtytWj0gAAAA1AZ/4dEN/AAAH707xoUTFQAXf\n",
              "PStwFPgy/a78I08uLdS7OjwAbVab3mEh4JS5TLS7z/Ma52cAAADPAZ/6akN/AAAH8KHxokFs8Hrv\n",
              "oAy80pG6REyc/hHZvtwBW/bT8fn/m0qXgVJYNgcNM3D2FUu4PUyz1r72TpSZSEdZ5YrnNvDNgpN7\n",
              "6EaYolgiTt9EmbX3xMzeTynt07GR4C+hSRLGV1AvnV4hl1J39e0C+a83PMq/km4xsNK9PORirDaD\n",
              "xJPtUAkkeoxRaDPR3FJPi343jIYP4EZgKzGg9uuS7jYTFVYUET5WRDQOLgbQjgtOGYUgfYVQEead\n",
              "0AkNZUEwM9vydvWdfg7wNF4EAAAAykGb/0moQWyZTAgj//61KoAAAAMAAAMDeTSQD5sgfGrpgKY8\n",
              "98PuSo4gAF8sgH4J/uXjFT/amGbIgNI2TweZpmLHlf+Ci5S50s1vvJaDvInx92A/aC3ghjqYec2D\n",
              "qgmcDoOSyqnqUh/CptyKoTWBGG+MsCMv/8Q3yJMlXEkUh/kOouuyf3iMdt8/siUm7qZqfdFOItJD\n",
              "VPWNm55wA0CwL7zXf/d8gQV6CjtZoiRBxXOdYth+eftg7iAkfeNntpRxm2nW7gFvYry8mhEAAADb\n",
              "QZ4dRRUsO/8AAAW5wv+yyqzO+igoIBwhS+s6SoMYbm2gFJugF8xNVCOH0cI0LrnuSH29+kazrT3S\n",
              "rAeTZ4wsaCa2IwdEZiYrozj9Y+BtFSsHrg/JgfapqEH32cgydSUeFYXuKFV4JfqKTzEZ0JSHsBMG\n",
              "IjHYpOBwjbLO+WnX/85LrVW7hYR5WMAHvf6H1B7Hiep9HW7J4pCoS+NjjLA/eahKnOCKaMUZ2yan\n",
              "IgsynuqeTqw1tEu2/wGJtCRar4QKmaxW29OYmUmQ2koz4wGaOQqva+41KyDlAAPTAAAAzgGePHRD\n",
              "fwAAB+9O8aFExUAF3z0reaU5oCaUa/nG38PgBGJ6oe0/9UcRpHg3df4zS+GIHI20rkNF120u4rpe\n",
              "XJhDDizfvWHCDOLsnCeArJLRc0A3xHoUUA8huAAsGiqo9o1oRtJfpy2yVMiyNydpxD6ZOEWJN5as\n",
              "Ljl6FvrzaxkTD+s0tgq8vgAG/kTxKobpOcYHTf81kU4TX+qKscNPPPurX9y0WhSlb3V7vqPr2KKg\n",
              "mlNx1Uil9wbnfhUwlTvEdwoTNcrkCTtXLACwALaAAAAAtwGePmpDfwAAB/Ch8aJBbPB676AMuD4Y\n",
              "F1GbdyXaUxfDJwAmmp/VjOxtp1zFoK9ls3I0DHm3D18jriHr6SEgXuclyDdzA3fZSdFJZ+uoRbfh\n",
              "bvXTDg8ZuLNaKKav1G3eoYBwYL6sHE2nxbyxijGKMeT6AWDCau3X+kwQuXkJ02gXKJZkibWRLVMG\n",
              "6m7W4r+vImkCiiUUGx1m1fejkkWHJXqhutzSVlWAAJCWvZKjqA+t6MLsko+B/gAAANpBmiNJqEFs\n",
              "mUwII//+tSqAAAADAAADASnmb+F8YQQAOvL3vkuX8TSPLITY4LYgM4w1VKt8ZoWnaALgx7F0lmEZ\n",
              "9WtbbbqLUHzDmBPJcObIuFQyPMi/JUWWsAkfhQwu8sQ+Yogc+/yXEcxpkUdvSZS83oX6W07zCYam\n",
              "vhieBSZzVyXS5hsZOY5VcSMZcKBu+ilkkZmV6fpH7h+0NLkexRr5JM6GZjpYutC02eQn7DtFEaZm\n",
              "jq/p1g6SsapALoaBcXGzHIXJPnKZjtFMmUvyFezgjlrOEBkiNB6JgQAAAMFBnkFFFSw7/wAABbnC\n",
              "/7LKrM76KCggHCFL3DaqjIA73FZy6pvFtACMrChQg5d7LFoVAE2CSiJ7jkR6nvWTNgFfZWl+Z0pj\n",
              "fSSMYhkEuPAGbKkYP67F6jlDBTPQ29vaCuL736zpg3qyw4LEhJiszdwb4icqzKuUkd1WAuySrCYR\n",
              "GKFdn3e7dPtfKdsYWOlSvj0jm/a1yuYFhLb/wTsGkxCKdH1KPpd/tUhs1yUpLqob5QedjxbukW3q\n",
              "0oez2Sa6dg9IAAAAWgGeYHRDfwAAB+9O8aFExUAF3z0rcCjwZCAC6ol3FnEEQuG6x1ilaQd/w6DA\n",
              "QN8zvgqL0kxPc6bkudFE22J/wtN9Qz2G0/3tsv2HS8y/di56OSC3qruTp8SKTwAAAL8BnmJqQ38A\n",
              "AAfwofGiQWzweu+gDLmbCeP5Kc/5+Ckp9wA3Q96KeLOeDgiOM0OXGoQjP/NWy4WxcM+hrmbPxTFK\n",
              "yAtvq/FYhnBFObQtsCb5VmFmNk8a7Xq0OM4BNdDnK9wt+Fvvf+9ubb5MlkqXsHwfQxU7amP8b3xL\n",
              "ON1yP5YuwcCnHg96zuQxgmtwv0OdEozSudMRv9hHKgIGals19i62ZKfcY/iMgpIKUeyzDL6olL26\n",
              "CTumie5mAKPeots1sAAAAOdBmmdJqEFsmUwII//+tSqAAAADABvtwfw+uCsAE1fReCGvK9+66yMZ\n",
              "zZspv1UJsqEfdEmL0CIB96Vvm8g+F9RH82pdHsiAPTaWzTtzYc41rUN3zCMQObZ0D/n8lydrpmL7\n",
              "0N/OwV2aKjKdBSENFHuVplHZyObCWM7q8GcoMXNTkmVrMxdf59Gr7ISld5JhdWPO6mPE8YG/If+N\n",
              "Id0SEcJHm4dRM52xSMtwV5tN10FDJrdG2WRFl1WspGdYFaxEwtZfG9lsbWpFGk5/KPMv62St4ltN\n",
              "9b7DFjAp7AkeaLQpOulJxuiLRSUAAADLQZ6FRRUsO/8AAAW5wv+yyqzO+ilkjvoJj7zFZmk1BrNj\n",
              "4KS+DADdD8uv4R/xSTHrtnQOn/7QxdhXyUru0yt8jrxqv9aWxXeRXIrJHaT1N8zbYr8gmpjp0YLD\n",
              "Vom0WV+q+QQ9ejdIl2d1V3t6U92AqVEcIL5KWBqI/ZS1cN2AddXXu40OAVP94dbOq+Ct66ziQ2NQ\n",
              "Gnr7khc3AeZhu2qQ8LjkhNLlMiDEir/SqSq7qS4h/t6e9O386+GfZvOkJGM7TXHLWqm9nZU4CgkA\n",
              "AADHAZ6kdEN/AAAH707xoUTFQAXfPS0AHzmgbfKlLAADj3Jdodrv0ZbPH2YI43aKBtlezgxu9xbQ\n",
              "T7T/NaowWCn0fpFUvrdgie/yVEkSYpPrh+ETNB6Bxh1bUyyg1I3kgc1BoxRd3Y3mEIAE6yvev2Zs\n",
              "Xi1s37ag7NVUNEaZsLKqajSjwwQW1cKXRp2SYwTENHly1SS6yZEzuQcyajP3TPrAHnvflG2V0EiJ\n",
              "EFQXeF5/98l1x8tV1apNe3Qh5gHFfiEryK64p8BgQQAAANIBnqZqQ38AAAfwofGiQWzwex+DgjUU\n",
              "oomTgKO7kxSP588ox3AALd7adog8ogbkbnFKuI0QpjafwPWSBmgq4InE4Bl9O9k5E2LsZgtXtah7\n",
              "uN42OIqhzPSQM1XEKI1WDE1dm7gomRXOlwHkJow68z5FWvgWOSX2YoPsEF1xVylW8yxnxfpP0UxE\n",
              "M2wQXlUGERJW8fJMpICy/trdxhkLC4zyYOqsO1E/i/TqT6pVfDOiKbfHaID0yTNDR25dpKWra/j1\n",
              "A3kqQWfTnzLUNtdgaT+ALKEAAADSQZqrSahBbJlMCCH//qpVAAADAAGeoTeANwi8lQg9eROspaeW\n",
              "ya7HQf8Pub2lXWAjkm6l8uBRdKyPlbbm3JB8/MFG+QDbbdkTUrXx/7mqbGeVCYe1SJcSLfFrVixv\n",
              "ta5RXRjcO7phc+mm5E23Y3aPJUPwEJ8qJyyzrZCo1UAphG9/91bM1Db1qC54mlPX7dCuFH77oU3F\n",
              "Moo/dg2yNIFw3+ckR8HytMHvcRytVgDT1gCC1R0DzoFfhH6SOzkf1/Ryt4DQrWGtLyKC0cUmnGQg\n",
              "ABiwAAAAzEGeyUUVLDv/AAAFucL/ssqtxy0gph3AhBGAEDXCAOi4vkAnu5wcxTZDt8YBSJ2yuNcc\n",
              "Pj10jUu+riZrSkFAGEJGWhrclZaLox0Pt5QW0BUXBzrw/IileHzVPe21QpWXSoeKC/6CMiS99i3Y\n",
              "SIIPFRwemhxXthi9UR0GVIB6i+APkmYilGRU9EY8PzEWEa0jRFYIEppVvV51/twnmcMOUsQNR3Hk\n",
              "c8uiWFrXYNxQ5fzElOWOUM7/4NRg0kRczMn7AB8S3jBAWiLYTsAFtAAAAMkBnuh0Q38AAAfvTvGh\n",
              "RN2TM0YHXJpJIvfEY2ooWUAAP6QfH5Ek+EQVGE3vlHCX8NKNgv3QAovyTlIChh2CQyBWLoamRHNP\n",
              "0AWNBK4mr0pjQK4Uw8ojE90qeJNGT48FDurJezxV3nKFstMW+f+mt3Jx03+qXAkYTJ+gcwR+ZRV2\n",
              "IFQJvavHX/pIPzXIVl5FyuubWejr76PjJ4WhLF0mfQTGLv9wa3mg2LR3DAjkj1E4ZJg3QOyt0PH2\n",
              "OmVb7hzB5PRk0P0MAoowAdMAAABGAZ7qakN/AAAH8KHxokF8udsBXmYLYEa8WM3dz2Xd9CtHCAC6\n",
              "X137aK+aw1tvTODCllDG15W5sLmqiODDqV0LdlzPKQAu4AAAAHBBmu1JqEFsmUwUTBD//qpVAAAD\n",
              "AAGg96lZLsNRiaYCzL2/4H/wAQN90FcADRsguLrIlE5JzIS8xkbdCmO+3YYdEVCewbJ9uism8C9R\n",
              "aKVdZaVXLy1AbBRWWaKABXWCTX2tIsGiyeyGIqorEHRoAAG1AAAAxQGfDGpDfwAAB/FKomivfFR4\n",
              "+9sBvW0I1yMVLznxV2+3DgAnWq8ChUiyYjMPF4GuZOSktMxTz3Ms3BSY2kcRrDzNYDm+dp9MBDG1\n",
              "AEczkEzrZKGz37P88LefHHniZ1mDeouPDlraVDvJTdx8ssQghRIoIRfDELxMEyUfazsVxlBtzb40\n",
              "ImTEo1tDYUqn5iAWbOi9cNtaGCHcmzxD9YN/s9MrNE/+ph+ws1ELO8LV+IC5HJt2Cq5/eM2TGq+I\n",
              "HNIOwERkAAEnAAAAzEGbEUnhClJlMCG//qeEAAADAASb5GreCI9zrG7c90vwe+NxADhH17kwnJuW\n",
              "tDAbKkjSYzyVMy9nZk0lsp6N33EthbGy0LDizT5SIZKmJydH7WMyAVrdiR29zCVPHX3YJjpgM9gs\n",
              "PQ7S+1iP/mM0so41xCCa8gqlU9OmCDQj2OBXrkI3JRCgn0/aW56sErJ32dlCjo7AXeJ4Aw7ybq66\n",
              "F0fuMEr6NUdYS0TqRh5Yc9HmkwW0mksoizDy3yPk7zmqoyIV/Y8Au7Je6AAEzQAAAMdBny9FNEw7\n",
              "/wAABbmLf7LB1CS7m82bQQ4/TlDDrSVlTneQ75jOecqx/792ABOtYjw36UvVFZOcuaRje1ORBlz8\n",
              "YXT8xe2DMuLFVrE6n98RrtiDKnreaAa9D++BjXynDRpTMZiIDQ3Be6HL478zyiOn2xb6LUnqC0TB\n",
              "KBnZFocqAs6J76Xy2fhsAZZblaGFP65kldQiJYvqyfoxJcwERqG5cpH9u+jOQewzeiwM+y5hjoNo\n",
              "O94rSltPQiHMGWPYBmr5YlIAAG9BAAAA2AGfTnRDfwAAB+9O8aFExUAIp7vDV7ALk2Yu1+v0Npmz\n",
              "4AWx/H88X9U171fPA+sYeeTaJ8U+LDYr8WFY6DRFhNKlu7p8FbbInvaVadCZBd4NHvtYfX2UIUby\n",
              "Unzg+ignNMQngSGh3gHs2corCcP51gTrjmYLWTjx7QtTMXAoPHgsKSTgDLKNJtowlc5jmUH1MqcK\n",
              "8fZSk/r1D7eYwAqV/n5v/caHKMwJaTYdiIilETZLDRgBSgYF5NVRH5fSbKlJOx3XrRzxHtU3aPtT\n",
              "EIyhLe/CepBQ2gAl4AAAAMYBn1BqQ38AAAfwofGiQWzwfFR5d2UjVJE1ZREZAgf/w/rwAXSdhKBx\n",
              "puYzX4KHiBeX5wkKy7jk6s5rVvd7giIq7tuIFgcuCwZwTX35DPpjY1i4irSQQe6JKBwCwz3WZ0wI\n",
              "zSL4lS35ri4xaTOOipBI9pjyA5lKsmZ/QMNy6vn0cGjLUv8GVSxFTtDI6d8jKUXa3t149EOgLI4w\n",
              "uyV0V6o3taRKgCNTeWB7HcqIlz7eoaGYIa+aZNYGMRjLqjUc/6QdmZmAB6wAAAWEbW9vdgAAAGxt\n",
              "dmhkAAAAAAAAAAAAAAAAAAAD6AAAE4gAAQAAAQAAAAAAAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAB\n",
              "AAAAAAAAAAAAAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAgAABK50cmFrAAAA\n",
              "XHRraGQAAAADAAAAAAAAAAAAAAABAAAAAAAAE4gAAAAAAAAAAAAAAAAAAAAAAAEAAAAAAAAAAAAA\n",
              "AAAAAAABAAAAAAAAAAAAAAAAAABAAAAAAlgAAAJYAAAAAAAkZWR0cwAAABxlbHN0AAAAAAAAAAEA\n",
              "ABOIAAAIAAABAAAAAAQmbWRpYQAAACBtZGhkAAAAAAAAAAAAAAAAAAAoAAAAyABVxAAAAAAALWhk\n",
              "bHIAAAAAAAAAAHZpZGUAAAAAAAAAAAAAAABWaWRlb0hhbmRsZXIAAAAD0W1pbmYAAAAUdm1oZAAA\n",
              "AAEAAAAAAAAAAAAAACRkaW5mAAAAHGRyZWYAAAAAAAAAAQAAAAx1cmwgAAAAAQAAA5FzdGJsAAAA\n",
              "uXN0c2QAAAAAAAAAAQAAAKlhdmMxAAAAAAAAAAEAAAAAAAAAAAAAAAAAAAAAAlgCWABIAAAASAAA\n",
              "AAAAAAABAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAAGP//AAAAN2F2Y0MBZAAW/+EA\n",
              "GmdkABas2UCYE3llhAAAAwAEAAADAFA8WLZYAQAGaOvjyyLA/fj4AAAAABx1dWlka2hA8l8kT8W6\n",
              "OaUbzwMj8wAAAAAAAAAYc3R0cwAAAAAAAAABAAAAMgAABAAAAAAUc3RzcwAAAAAAAAABAAAAAQAA\n",
              "AZhjdHRzAAAAAAAAADEAAAABAAAIAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAA\n",
              "AQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAAB\n",
              "AAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAEAAAAAACAAAEAAAAAAEA\n",
              "ABQAAAAAAQAACAAAAAABAAAAAAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAA\n",
              "BAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAAAAABAAAEAAAAAAEAABQAAAAAAQAACAAAAAABAAAA\n",
              "AAAAAAEAAAQAAAAAAQAAFAAAAAABAAAIAAAAAAEAAAAAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgA\n",
              "AAAAAQAAAAAAAAABAAAEAAAAAAEAAAwAAAAAAQAABAAAAAABAAAUAAAAAAEAAAgAAAAAAQAAAAAA\n",
              "AAABAAAEAAAAABxzdHNjAAAAAAAAAAEAAAABAAAAMgAAAAEAAADcc3RzegAAAAAAAAAAAAAAMgAA\n",
              "B8QAAAD4AAAAWwAAAFQAAABjAAAA7QAAAM4AAADDAAAAVAAAAMkAAADFAAAA1QAAAM8AAADgAAAA\n",
              "ywAAAM4AAADSAAAAywAAANkAAADQAAAAwAAAAFAAAAA3AAAAbAAAAMMAAADcAAAAOQAAANMAAADO\n",
              "AAAA3wAAANIAAAC7AAAA3gAAAMUAAABeAAAAwwAAAOsAAADPAAAAywAAANYAAADWAAAA0AAAAM0A\n",
              "AABKAAAAdAAAAMkAAADQAAAAywAAANwAAADKAAAAFHN0Y28AAAAAAAAAAQAAADAAAABidWR0YQAA\n",
              "AFptZXRhAAAAAAAAACFoZGxyAAAAAAAAAABtZGlyYXBwbAAAAAAAAAAAAAAAAC1pbHN0AAAAJal0\n",
              "b28AAAAdZGF0YQAAAAEAAAAATGF2ZjU4Ljc2LjEwMA==\n",
              "\">\n",
              "  Your browser does not support the video tag.\n",
              "</video>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 600x600 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Create environment with obstacles in state\n",
        "env = PointParticleEnv()\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "from IPython.display import HTML\n",
        "\n",
        "def run_random_agent_animation(env, steps=500):\n",
        "    frames = []\n",
        "    state = env.reset()\n",
        "    for _ in range(steps):\n",
        "        # Sample a random action from the continuous action space\n",
        "        action = env.action_space.sample()\n",
        "        state, reward, done,_, info = env.step(action)\n",
        "        frame = env.render(mode='rgb_array')\n",
        "        frames.append(frame)\n",
        "        if done:\n",
        "            break\n",
        "    return frames\n",
        "\n",
        "# Create environment instance (with obstacles and continuous actions)\n",
        "env = PointParticleEnv(obs=True)\n",
        "\n",
        "# Run the agent for 50 random steps and collect frames\n",
        "frames = run_random_agent_animation(env, steps=50)\n",
        "\n",
        "# Create animation using matplotlib\n",
        "fig, ax = plt.subplots(figsize=(6, 6))\n",
        "ax.axis('off')\n",
        "im = ax.imshow(frames[0])\n",
        "\n",
        "def update(frame):\n",
        "    im.set_data(frame)\n",
        "    return [im]\n",
        "\n",
        "anim = animation.FuncAnimation(fig, update, frames=frames, interval=100, blit=True)\n",
        "\n",
        "# Display animation as HTML video (for Jupyter notebooks)\n",
        "HTML(anim.to_html5_video())\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ujBgisU_UWuE"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import wandb\n",
        "import gym\n",
        "import json\n",
        "import torch\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from src.utils import *\n",
        "from src.memory import *\n",
        "from src.agents import *\n",
        "\n",
        "os.environ['WANDB_API_KEY'] = ''\n",
        "class Trainer:\n",
        "\n",
        "    def __init__(self, config_file, enable_logging=True):\n",
        "        self.enable_logging = enable_logging\n",
        "        self.config = Trainer.parse_config(config_file)\n",
        "        self.env =  gym.make(self.config['env_name'])\n",
        "        self.env = apply_seed(self.env,self.config['seed'])\n",
        "        self.state_dimension = self.env.observation_space.shape[0]\n",
        "        print(\"state\",self.state_dimension)\n",
        "        self.action_dimension = self.env.action_space.shape[0]\n",
        "        self.max_action = float(self.env.action_space.high[0])\n",
        "        self.device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
        "        self.agent = DDPGAgent(\n",
        "            state_dim=self.state_dimension, action_dim=self.action_dimension,\n",
        "            max_action=self.max_action, device=self.device,\n",
        "            discount=self.config['discount'], tau=self.config['tau']\n",
        "        )\n",
        "        self.save_file_name = f\"DDPG_{self.config['env_name']}_{self.config['seed']}\"\n",
        "        self.memory = ReplayBuffer()\n",
        "        if self.enable_logging:\n",
        "            wandb.init(project=\"ddpg\", config=self.config)\n",
        "        try:\n",
        "            os.mkdir('./pretrained_models')\n",
        "        except Exception as e:\n",
        "            pass\n",
        "\n",
        "    @staticmethod\n",
        "    def parse_config(json_file):\n",
        "        with open(json_file, 'r') as f:\n",
        "            configs = json.load(f)\n",
        "        return configs\n",
        "\n",
        "    def train(self):\n",
        "        state, info = self.env.reset()\n",
        "        done = False\n",
        "        episode_reward = 0\n",
        "        episode_timesteps = 0\n",
        "        episode_num = 0\n",
        "        evaluations = []\n",
        "        episode_rewards = []\n",
        "        for ts in tqdm(range(1, int(self.config['time_steps']) + 1)):\n",
        "            episode_timesteps += 1\n",
        "            if ts < self.config['start_time_step']:\n",
        "                action = self.env.action_space.sample()\n",
        "            else:\n",
        "                action = (\n",
        "                        self.agent.select_action(np.array(state)) + np.random.normal(\n",
        "                    0, self.max_action * self.config['expl_noise'],\n",
        "                    size=self.action_dimension\n",
        "                )\n",
        "                ).clip(\n",
        "                    -self.max_action,\n",
        "                    self.max_action\n",
        "                )\n",
        "            next_state, reward, done, trunc, info = self.env.step(action)\n",
        "            self.memory.push(\n",
        "                state, action,reward, next_state,\n",
        "                float(done) if episode_timesteps < self.env._max_episode_steps else 0)\n",
        "            state = next_state\n",
        "            episode_reward += reward\n",
        "            if ts >= self.config['start_time_step']:\n",
        "                self.agent.train(self.memory, self.config['batch_size'])\n",
        "            if done:\n",
        "                if self.enable_logging:\n",
        "                    wandb.log({'Episode Reward': episode_reward, 'Timesteps': ts})\n",
        "                episode_rewards.append(episode_reward)\n",
        "                state, info = self.env.reset()\n",
        "                done = False\n",
        "                episode_reward = 0\n",
        "                episode_timesteps = 0\n",
        "                if episode_num % 100 == 0 and episode_num > 0:\n",
        "                    evaluations.append(evaluate_policy(self.agent, self.config['env_name'], self.config['seed'],enable_logging=self.enable_logging,wandb=wandb))\n",
        "                    self.agent.save_checkpoint(f\"./pretrained_models/{self.save_file_name}\")\n",
        "                episode_num += 1\n",
        "        wandb.finish()\n",
        "        return episode_rewards, evaluations\n",
        "\n",
        "    def evaluate(self):\n",
        "        self.agent.load_checkpoint(f\"./pretrained_models/DDPG_{self.config['env_name']}_{self.config['seed']}\")\n",
        "        evaluate_policy(self.agent, self.config['env_name'], self.config['seed'],render=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "TgpYB1mYVzyT",
        "outputId": "c136b464-88c9-4754-df35-406211e86e55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "state 3\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/gym/envs/registration.py:498: UserWarning: \u001b[33mWARN: Overriding environment PointParticle-v0 already in registry.\u001b[0m\n",
            "  logger.warn(f\"Overriding environment {new_spec.id} already in registry.\")\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">clear-fire-12</strong> at: <a href='https://wandb.ai/voldigoadanos53-aligarh-muslim-university/ddpg/runs/h8l0y2ig' target=\"_blank\">https://wandb.ai/voldigoadanos53-aligarh-muslim-university/ddpg/runs/h8l0y2ig</a><br> View project at: <a href='https://wandb.ai/voldigoadanos53-aligarh-muslim-university/ddpg' target=\"_blank\">https://wandb.ai/voldigoadanos53-aligarh-muslim-university/ddpg</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20250617_181442-h8l0y2ig/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.20.1"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/drive/MyDrive/Projects/rl/DDPG-Pytorch/wandb/run-20250617_182919-ijvwjdii</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/voldigoadanos53-aligarh-muslim-university/ddpg/runs/ijvwjdii' target=\"_blank\">skilled-oath-13</a></strong> to <a href='https://wandb.ai/voldigoadanos53-aligarh-muslim-university/ddpg' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/voldigoadanos53-aligarh-muslim-university/ddpg' target=\"_blank\">https://wandb.ai/voldigoadanos53-aligarh-muslim-university/ddpg</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/voldigoadanos53-aligarh-muslim-university/ddpg/runs/ijvwjdii' target=\"_blank\">https://wandb.ai/voldigoadanos53-aligarh-muslim-university/ddpg/runs/ijvwjdii</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/1000000 [00:00<?, ?it/s]/usr/local/lib/python3.11/dist-packages/gym/utils/passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
            "  if not isinstance(terminated, (bool, np.bool8)):\n",
            " 12%|█▏        | 115032/1000000 [1:00:01<14:22:31, 17.10it/s]"
          ]
        }
      ],
      "source": [
        "# from train import Trainer\n",
        "from matplotlib import pyplot as plt\n",
        "import gym\n",
        "from gym.envs.registration import register\n",
        "gym.register(\n",
        "    id='PointParticle-v0',\n",
        "    entry_point=PointParticleEnv,   # or \"__main__:PointParticleEnv\"\n",
        "    max_episode_steps=500    # ← choose a sensible episode length\n",
        ")\n",
        "\n",
        "\n",
        "env_name='PointParticle-v0'\n",
        "trainer = Trainer(config_file=f'./configs/{env_name}.json',enable_logging=True)\n",
        "episode_rewards, evaluations = trainer.train()\n",
        "\n",
        "plt.figure(figsize=(16, 10))\n",
        "plt.plot(episode_rewards)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sl8f57wRbe0-"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}